Chuyên đề 4 : Tiền xử lí dữ liệu 

Mục đích : Chuyên đề này đề cập đến chủ đề quan trong bật nhất trong Khoa Học Dữ Liệu và Máy Học. Công việc này chiếm hết 80% thời gian bạn làm việc , nghĩa là nếu thực hiện bước này thành công ban đã thành công 80%.

Phần 1: Tiền xử lí dữ liệu và Chuẩn bị dữ liệu.

Vậy tại sao chúng ta lại phải đi xử lí dữ liệu?
-Bởi vì khi chúng ta thực hiện thu thập dữ liệu trong thực tế , dữ liệu của chúng ta chứa rất nhiều "Rác" . Nó sẽ gặp các vấn đề :
--Dữ liệu bị thiếu (Missing Value) : rất nhiều trường dữ liệu bị thiếu. Ví dụ: Một khách hàng không điền tuổi , một sản phẩm không có mô tả...
--Dữ liệu không nhất quán : dữ liệu thường rất bề bộn và không nhất quán. Ví dụ : Đơn hàng có trường địa chỉ giao hàng có thể có người sẽ điền là TP.HCM nhưng cũng có người sẽ điền là Hồ Chí Minh ....
--Dữ liệu nhiễu : Chứa các lỗi hoặc các giá trị ngoại lai. Ví dụ : Ở cột tuổi xuất hiện giá trị 200 , hoặc một người có chiều cao 3 mét ....
--Nhiều định dạng khác nhau : hình ảnh , âm thanh , văn bản ,....
==> Để mô hình có thể hiểu , học và cho ra được kết quả như mong muốn ta phải thực hiện cải thiện dữ liệu đầu vào.

Các bước thực hiện : 
Vì máy tính chỉ có thể hiểu số , nó không hiểu chữ viết , nên ta phải quy đổi các dữ liệu đầu vào thành số , và công việc này được gọi là "Số Hóa" dữ liệu.
--Ordinal Encoding (Mã hóa có thứ tự) : Dùng khi các giá trị hơn kém , có thứ tự nhiên. Ví dụ :  Đánh giá sản phẩm : Kém , Trung Bình , Tốt , Tuyệt Vời . Ta có thể mã hóa 1,2,3,4.
--One-Hot Encoding (Mã hóa Nóng ): Dùng khi các giá trị không có thự tứ , chúng nó ngang hàng. Ví dụ có 3 quốc gia USA , UK, France khi tiến hành mã hóa thành 1,2,3 , nó sẽ ngầm hiểu France(3) > UK(2) điều này hoàn toàn vô nghĩa. => Cách làm : nó sẽ tạo ra bản ghi US =0 , UK = 1 , FRANCE = 3 , bằng cách này mọi quốc gia điều bình đẳng.
Mẹo thực chiến : Để tránh đa cộng tuyển , ngta thường dùng Dummy Encoding để mã hóa Dummy Enconding: N-1 cho N giá trị.

Thang đo: Vì sao lại dùng thang đo ? Bởi vì có những trường dữ liệu rất lớn , nếu để nguyên mô hình máy học sẽ có nguy cơ bị sai , hay quá tải , vì thế nên chúng ta phải thực hiện Tái Định Thanh Đo.

Các phương pháp Tái định :
Normalization (Min-Max Scaling) : phương pháp này sẽ ép tất cả giá trị vào một khoảng dự trên MIN(X) và MAX(X) . Rất đơn giản và hiệu quả.
Standardization (Z-score) :  Phương pháp này biển đổi dữ liệu sao cho nó có trung bình (mean ) bằng 0 và độ lệch chuẩn là 1 .

?? Vậy lúc nào sử dụng cái nào ?
- Dùng MIN-MAX Scaling khi bạn biết được bộ dữ liệu của bạn không có nhiều giá trị ngoại lai. Các thuật toán như K-Nearest Neighbors(KNN) , Neural Netwrorks thường ưa chuộng phương pháp này.
- Dùng Z-core khi dữ liệu của bạn có outlier hoặc khi bạn muốn dữ liệu tuân theo phân phối chuẩn. Thông thường các thuật toán dựa trên khoảng cách như SVM , PCA thường hoạt động tốt hơn với phương pháp này.
==> Quy tắc vàng nếu phân vân hãy thử cả hai.

Phương pháp nhóm.
Giả định ta đang có một cột Tuổi với phân bố từ [18-80] , thay vì sử dụng toàn bộ dữ liệu như thế này , ta có thể chia thành các nhóm : Thanh niên(18-27) , Trung niên(27-45) ,Lớn tuổi(45<)
Điều này giúp gì ?
-- Giúp một số thuật toán như Cây Quyết Định hoạt động hiệu quả hơn.
-- Giảm tác động của các giá trị ngoại lai.
-- Dễ nắm bắt hơn và gọn hơn.

Cạm bẫy : Rò rỉ thông tin?
QUY TẮC SỐNG CÒN : 
--split : chia tập dữ liệu thành tập Train , Validation , Test.
-- flit : Học các tham số tiền xử lí dữ liệu chỉ trên tập TRAIN
-- Transform : áp dụng các phép biến đổi đã học cho tập Train , Validation và Test

Phần 2 : Thao Tác Đặc Trưng - Biến dữ liệu thành Vàng

1. Lựa chọn đặc trưng 
Các phương pháp phổ biến : 
- Filter Methods (Bộ lọc) : Đánh giá các đặc trưng qua các chỉ số thống kê. Nhanh gọn nhưng bỏ qua các mối quan hệ giữa các đặc trưng.
- Bao bọc : Thử và sai . Tiến hành thử các bộ đặc trưng khác nhau , huấn luyện mô hình và xem tập nào cho kết quả tốt nhất.
- Embedded Methods (Tích hợp): Lựa chọn các đặc trưng được tích hợp ngay trong quá trình huấn luyện mô hình.
2. Trích xuất đặc trưng.
- Tạo ra một tập đặc trưng mới , thường có số chiều nhỏ hơn , từ các dặc trưng ban đầu.
3. Xây dựng đặc trưng.
- Tạo đặc trưng mới có ý nghĩa suy ra từ các đặc trưng có sẵn .


==> Work Flow chuẩn :
-- Hiểu dữ liệu (EDA)
-- Chia dữ liệu (Train/ Validation/ Test)
-- Xử lí mising trên data , rồi áp dụng cho các tập còn lại.
-- Enconding type categorial trên tập Train , rồi áp dụng cho các tập còn lại.
-- Scale biến numerical trên tập Train , áp dụng cho các tập còn lại.
-- Lựa chọn / Trích xuất/ Xây dựng đặc trưng
-- Train mô hình

